{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy \n",
    "access_token = \"318256106-lLR709QO7OzkUSQ549ji1bKzuCggcaNBbdDJkq9U\"\n",
    "access_token_secret = \"cm14qVXM45PCsEutAp8a2haKgTAzwClkS55XusLUXlodO\"\n",
    "consumer_key = \"ObXTJ4Qwrt9rnDr1SlbYAF1nu\"\n",
    "consumer_secret = \"oU1BOffC7zOoqXsCuiBXw5ul3vHAjyK2XgyeRF156HG1Z0rbTs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "donald_raw = pd.read_csv('Donald-Tweets!.csv')\n",
    "donald_raw.columns = [i.lower() for i in donald_raw.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "donald = donald_raw[donald_raw.type == 'text']\n",
    "user_tweets = donald.tweet_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "#auth.set_access_token(access_token, access_token_secret)\n",
    "#\n",
    "#api = tweepy.API(auth)\n",
    "##user = api.get_user('kanyewest')\n",
    "##\n",
    "##\n",
    "#### Get Elon's Tweets\n",
    "###stuff = api.user_timeline(screen_name = 'elonmusk', count = 5000, include_rts = False)\n",
    "###user_tweets = [i.text for i in  stuff]\n",
    "##    \n",
    "### Get The People Elon Follows\n",
    "#users_friends = [i for i in api.friends_ids(screen_name = 'realDonaldTrump')]\n",
    "#\n",
    "#\n",
    "###Getting 2nd degree followers\n",
    "#second_degree_friends = []\n",
    "#for ids in users_friends[:35]:\n",
    "#    second_degree_friends.extend([i for i in api.friends_ids(id = ids, count = 20)])\n",
    "#\n",
    "#   \n",
    "#final_second_degree_friends = [i for i in second_degree_friends if i not in set(users_friends)]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_second_degree_friends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "second_degree_friends_user_names = []\n",
    "\n",
    "for i,friend_ids in enumerate(final_second_degree_friends[:50]):\n",
    "    try:\n",
    "        second_degree_friends_user_names.append(api.get_user(friend_ids).screen_name )\n",
    "        print i\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exclude = ('womenfortrump', 'fema', 'flotus', 'potus', 'huffpost', 'secondlady', \n",
    "           'realdonaldtrump', 'VPPressSec', 'axios', 'vppresssec', 'oann', 'noaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_second_degree_screen_name = [i for i in second_degree_friends_user_names if i.lower() not in exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'VPComDir',\n",
       " u'UchtdorfDF',\n",
       " u'LDSchurch',\n",
       " u'MeghanReckling',\n",
       " u'ScottJenningsKY',\n",
       " u'Surabees',\n",
       " u'JohnInhulsen',\n",
       " u'max_docksey',\n",
       " u'KamilahPrince',\n",
       " u'SandraSmithFox',\n",
       " u'mikeallen',\n",
       " u'ron_fournier',\n",
       " u'brianjameswalsh',\n",
       " u'thejtlewis',\n",
       " u'cvpayne',\n",
       " u'KyleKashuv',\n",
       " u'NoviWolverine',\n",
       " u'NicholasTrainer',\n",
       " u'caitlinconant',\n",
       " u'mitchellreports',\n",
       " u'chucktodd',\n",
       " u'costareports',\n",
       " u'jdawsey1',\n",
       " u'Liz_Wheeler',\n",
       " u'VictorJoecks',\n",
       " u'Surabees',\n",
       " u'edhenry',\n",
       " u'benshapiro',\n",
       " u'reingowsky',\n",
       " u'PARISDENNARD',\n",
       " u'DineshDSouza',\n",
       " u'chuckwoolery',\n",
       " u'emilychangtv',\n",
       " u'specialkharvey',\n",
       " u'thebradfordfile',\n",
       " u'paulsperry_',\n",
       " u'CraigCaplan',\n",
       " u'RealCandaceO']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_second_degree_screen_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting 2nd degree connection tweets    \n",
    "second_degree_tweets = {}\n",
    "for screen_name in final_second_degree_screen_name[-10:]:\n",
    "    try:\n",
    "        stuff = api.user_timeline( screen_name= screen_name, count = 200, include_rts = False)\n",
    "        second_degree_tweets[screen_name] = [i.text for i in  stuff]    \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users_friends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(second_degree_friends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(second_degree_tweets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(second_degree_tweets.values()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean & Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-88ccfdabf41a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trump\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unicode-escape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "nlp.vocab[\"trump\".decode('unicode-escape')].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>type</th>\n",
       "      <th>media_type</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>twt_favourites_is_this_like_question_mark</th>\n",
       "      <th>retweets</th>\n",
       "      <th>unnamed: 10</th>\n",
       "      <th>unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16-11-11</td>\n",
       "      <td>15:26:37</td>\n",
       "      <td>Today we express our deepest gratitude to all ...</td>\n",
       "      <td>text</td>\n",
       "      <td>photo</td>\n",
       "      <td>ThankAVet</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
       "      <td>127213</td>\n",
       "      <td>41112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16-11-11</td>\n",
       "      <td>13:33:35</td>\n",
       "      <td>Busy day planned in New York. Will soon be mak...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
       "      <td>141527</td>\n",
       "      <td>28654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16-11-11</td>\n",
       "      <td>11:14:20</td>\n",
       "      <td>Love the fact that the small groups of protest...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
       "      <td>183729</td>\n",
       "      <td>50039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16-11-11</td>\n",
       "      <td>2:19:44</td>\n",
       "      <td>Just had a very open and successful presidenti...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/796...</td>\n",
       "      <td>214001</td>\n",
       "      <td>67010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16-11-11</td>\n",
       "      <td>2:10:46</td>\n",
       "      <td>A fantastic day in D.C. Met with President Oba...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/796...</td>\n",
       "      <td>178499</td>\n",
       "      <td>36688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date      time                                         tweet_text  \\\n",
       "0  16-11-11  15:26:37  Today we express our deepest gratitude to all ...   \n",
       "1  16-11-11  13:33:35  Busy day planned in New York. Will soon be mak...   \n",
       "2  16-11-11  11:14:20  Love the fact that the small groups of protest...   \n",
       "3  16-11-11   2:19:44  Just had a very open and successful presidenti...   \n",
       "4  16-11-11   2:10:46  A fantastic day in D.C. Met with President Oba...   \n",
       "\n",
       "   type media_type   hashtags      tweet_id  \\\n",
       "0  text      photo  ThankAVet  7.970000e+17   \n",
       "1  text        NaN        NaN  7.970000e+17   \n",
       "2  text        NaN        NaN  7.970000e+17   \n",
       "3  text        NaN        NaN  7.970000e+17   \n",
       "4  text        NaN        NaN  7.970000e+17   \n",
       "\n",
       "                                           tweet_url  \\\n",
       "0  https://twitter.com/realDonaldTrump/status/797...   \n",
       "1  https://twitter.com/realDonaldTrump/status/797...   \n",
       "2  https://twitter.com/realDonaldTrump/status/797...   \n",
       "3  https://twitter.com/realDonaldTrump/status/796...   \n",
       "4  https://twitter.com/realDonaldTrump/status/796...   \n",
       "\n",
       "   twt_favourites_is_this_like_question_mark  retweets  unnamed: 10  \\\n",
       "0                                     127213     41112          NaN   \n",
       "1                                     141527     28654          NaN   \n",
       "2                                     183729     50039          NaN   \n",
       "3                                     214001     67010          NaN   \n",
       "4                                     178499     36688          NaN   \n",
       "\n",
       "   unnamed: 11  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donald.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-2a4c805927f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtokenized_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muser_tweets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtokenized_tweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unicode-escape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m \u001b[0;31m# we want to keep each tweet seperate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenized_tweets = []\n",
    "for tweet in user_tweets:\n",
    "    tokenized_tweet = nlp(tweet.decode('unicode-escape'))\n",
    "    \n",
    "    tweet = \"\" # we want to keep each tweet seperate\n",
    "    \n",
    "    for token in tokenized_tweet:\n",
    "        if token.is_space:\n",
    "            continue\n",
    "        elif token.is_punct:\n",
    "            continue\n",
    "        elif token.is_stop:\n",
    "            continue\n",
    "        elif token.is_digit:\n",
    "            continue\n",
    "        elif len(token) == 1:\n",
    "            continue\n",
    "        elif len(token) == 2:\n",
    "            continue\n",
    "        elif '@' in str(token):\n",
    "            continue\n",
    "            \n",
    "        elif 'http' in str(token):\n",
    "            continue\n",
    "        elif 'amp' in str(token):\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                tweet += str(token.lemma_) + \" \" #creating lemmatized version of tweet\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "    tokenized_tweets.append(tweet)\n",
    "tokenized_tweets = list(map(str.strip, tokenized_tweets)) # strip whitespace\n",
    "tokenized_tweets = [x for x in tokenized_tweets if x != \"\"] # remove empty entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Broadly, LDA requires a Dictionary object that is later used to create a matrix called a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this makes a list of lists\n",
    "gensim_tweets = []\n",
    "for tweet in tokenized_tweets:\n",
    "    gensim_tweets.append(tweet.replace('-PRON- ', '').replace('trump ', '').replace('the ', '').split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dictionary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-dbbb295b14b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#creates a gensim dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgensim_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgensim_tweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#removes really rare words and really frequent words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dictionary' is not defined"
     ]
    }
   ],
   "source": [
    "#creates a gensim dictionary \n",
    "\n",
    "gensim_dict = Dictionary(gensim_tweets)\n",
    "\n",
    "#removes really rare words and really frequent words\n",
    "gensim_dict.filter_extremes(no_below=5, no_above=0.7)\n",
    "\n",
    "#remove spaces between the  removed words\n",
    "gensim_dict.compactify() # remove gaps after words that were removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'num_terms'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-fcbe511fe7f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_terms\u001b[0m \u001b[0;31m# the number of terms in our corpus!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_docs\u001b[0m \u001b[0;31m# the number of documets. These are the number of tweets!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'num_terms'"
     ]
    }
   ],
   "source": [
    "corpus = [gensim_dict.doc2bow(i) for i in gensim_tweets ]\n",
    "\n",
    "\n",
    "print corpus.num_terms # the number of terms in our corpus!\n",
    "print corpus.num_docs # the number of documets. These are the number of tweets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_dict[448]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lda = LdaMulticore(corpus, num_topics=30, id2word=gensim_dict, chunksize=2000, workers=100, passes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### find a way to optimize the number of topics for trump and friend.\n",
    "# Make a way to automate and recommend\n",
    "#write a summary of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Coherence of The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate the # of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        \n",
    "        model=LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "        print num_topics\n",
    "\n",
    "    return model_list, coherence_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=40; start=1; step=5;\n",
    "\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=gensim_dict, \n",
    "                                                        corpus=corpus,\n",
    "                                                        texts=gensim_tweets, start=start,\n",
    "                                                        limit=limit, step=step)\n",
    "# Show graph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_topics=14\n",
    "\n",
    "lda = LdaModel(corpus, num_topics=num_topics, id2word=gensim_dict)\n",
    "\n",
    "for i in range(num_topics):\n",
    "    print i,  [(i[0],i[1]) for i in lda.show_topic(i, topn = 10)]\n",
    "    print '----'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from collections import Counter\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Data Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clean Data (Tokenize, Stem, Lemmitize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    tokenized_tweets = []\n",
    "    for tweet in user_tweets:\n",
    "        tokenized_tweet = nlp(tweet.decode('unicode-escape'))\n",
    "\n",
    "        tweet = \"\" # we want to keep each tweet seperate\n",
    "\n",
    "        for token in tokenized_tweet:\n",
    "            if token.is_space:\n",
    "                continue\n",
    "            elif token.is_punct:\n",
    "                continue\n",
    "            elif token.is_stop:\n",
    "                continue\n",
    "            elif token.is_digit:\n",
    "                continue\n",
    "            elif len(token) == 1:\n",
    "                continue\n",
    "            elif len(token) == 2:\n",
    "                continue\n",
    "            elif '@' in str(token):\n",
    "                continue\n",
    "\n",
    "            elif 'http' in str(token):\n",
    "                continue\n",
    "            elif 'amp' in str(token):\n",
    "                continue\n",
    "            else:\n",
    "                try:\n",
    "                    tweet += str(token.lemma_) + \" \" #creating lemmatized version of tweet\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        tokenized_tweets.append(tweet)\n",
    "    tokenized_tweets = list(map(str.strip, tokenized_tweets)) # strip whitespace\n",
    "    tokenized_tweets = [x for x in tokenized_tweets if x != \"\"] # remove empty entries\n",
    "    \n",
    "    gensim_tweets = []\n",
    "    for tweet in tokenized_tweets:\n",
    "        gensim_tweets.append(tweet.replace('-PRON- ', '').replace('the ', '').split(' '))\n",
    "    \n",
    "    return tokenized_tweets, gensim_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dict (tokenized_tweets):\n",
    "    gensim_dict = Dictionary(tokenized_tweets)\n",
    "\n",
    "    #removes really rare words and really frequent words\n",
    "    gensim_dict.filter_extremes(no_below=5, no_above=0.7)\n",
    "\n",
    "    #remove spaces between the  removed words\n",
    "    gensim_dict.compactify() # remove gaps after words that were removed\n",
    "    \n",
    "    return gensim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_corpus (dictionary, tokenized_text):\n",
    "\n",
    "    corpus = [dictionary.doc2bow(i) for i in tokenized_text ]\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Model (Pick # Of Topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        \n",
    "        model=LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lda(dictionary, corpus, tokenized_text):\n",
    "    limit=40; start=1; step=3;\n",
    "\n",
    "    model_list, coherence_values = compute_coherence_values(dictionary=dictionary, \n",
    "                                                        corpus=corpus,\n",
    "                                                        texts=tokenized_text, start=start,\n",
    "                                                        limit=limit, step=step)\n",
    "    x = range(start, limit, step)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i,value in enumerate(coherence_values):\n",
    "        if (value >= max(coherence_values) *.95) & (value <= max(coherence_values) ):\n",
    "            optimal_num = x[i]\n",
    "            break    \n",
    "\n",
    "        \n",
    "    num_topics=optimal_num\n",
    "\n",
    "    lda = LdaModel(corpus, num_topics=num_topics, id2word=text_dictionary)\n",
    "    \n",
    "    return lda, x \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Get Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_topics(lda):\n",
    "    temp_dict = {}\n",
    "\n",
    "    for o in range(lda.num_topics):\n",
    "        temp_dict[o] =   [i[0] for i in lda.show_topic(o, topn = 10)]\n",
    "        \n",
    "    return temp_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5. Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets, tokenized_tweets = clean_text(user_tweets)\n",
    "text_dictionary = create_dict(tokenized_tweets)\n",
    "corpus = create_corpus(text_dictionary, tokenized_tweets)\n",
    "lda = run_lda(text_dictionary, corpus, tokenized_tweets)\n",
    "trump_topics = get_topics(lda)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print lda.num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get For His Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_tweets, tokenized_tweets = clean_text(user_tweets)\n",
    "text_dictionary = create_dict(tokenized_tweets)\n",
    "corpus = create_corpus(text_dictionary, tokenized_tweets)\n",
    "lda = run_lda(text_dictionary, corpus, tokenized_tweets)\n",
    "trump_topics = get_topics(lda)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = {}\n",
    "\n",
    "for o in range(lda.num_topics):\n",
    "    temp_dict[o] =   [i[0] for i in lda.show_topic(o, topn = 10)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "for i in temp_dict.keys():\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [u'candidate', u'word', u'run', u'thank', u'presidential', u'bad', u'trump2016', u'makeamericagreatagain', u'success', u'work']\n",
      "1 [u'matter', u'makeamericagreatagain', u'poll', u'silent', u'new', u'establishment', u'john', u'this', u'trump2016', u'long']\n",
      "2 [u'great', u'make', u'america', u'again', u'trump', u'poll', u'thank', u'national', u'true', u'people']\n",
      "3 [u'trump', u'book', u'know', u'get', u'vote', u'donaldtrump', u'interview', u'a.m.', u'debate', u'say']\n",
      "4 [u'makeamericagreatagain', u'thank', u'trump2016', u'trump', u'great', u'people', u'donald', u'america', u'love', u'support']\n",
      "5 [u'vet', u'veteran', u'medium', u'correct', u'politically', u'liberal', u'attack', u'poll', u'know', u'say']\n",
      "6 [u'trump', u'trump2016', u'donald', u'border', u'thank', u'give', u'want', u'makeamericagreatagain', u'job', u'hillary']\n",
      "7 [u'trump', u'country', u'politician', u'like', u'career', u'america', u'debate', u'year', u'gop', u'cut']\n",
      "8 [u'trump', u'big', u'win', u'crowd', u'veteran', u'leave', u'like', u'will', u'great', u'new']\n",
      "9 [u'will', u'interview', u'tonight', u'great', u'enjoy', u'day', u'old', u'double', u'host', u'fox']\n",
      "10 [u'trump', u'president', u'donald', u'reagan', u'say', u'mr.', u'walker', u'good', u'time', u'know']\n",
      "11 [u'mccain', u'look', u'love', u'veterans', u'forward', u'listen', u'just', u'not', u'go', u'straight']\n",
      "12 [u'trump', u'truth', u'need', u'rubio', u'tell', u'like', u'poll', u'talk', u'tired', u'leader']\n"
     ]
    }
   ],
   "source": [
    "for i in temp_dict.keys():\n",
    "    print i, temp_dict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[823367015830323201, 818927131883356161, 471672239]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_degree_tweets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'President Donald J. Trump meets with members of Congress at a Renewable Fuel Standards announcement Tuesday, Oct. 9\\u2026 https://t.co/o6oPpyMeqB',\n",
       " u'Congratulations to our 114th Supreme Court Justice, Brett M. Kavanaugh! #SCOTUS\\U0001f3db\\U0001f1fa\\U0001f1f8\\n\\n\\U0001f51f\\U0001f4f8https://t.co/c3YdNNcU7c https://t.co/Aja93ejuw1']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_degree_tweets[823367015830323201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "7\n",
      "10\n",
      "13\n",
      "16\n",
      "19\n",
      "22\n",
      "25\n",
      "28\n",
      "31\n",
      "34\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "limit=40; start=1; step=3;\n",
    "\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=text_dictionary, \n",
    "                                                        corpus=corpus,\n",
    "                                                        texts=tokenized_tweets, start=start,\n",
    "                                                        limit=limit, step=step)\n",
    "x = range(start, limit, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.087748463245998512,\n",
       " 0.27602833653626963,\n",
       " 0.29078816132859481,\n",
       " 0.29676766732310988,\n",
       " 0.32605431730035755,\n",
       " 0.3469741567794683,\n",
       " 0.31104751486139892,\n",
       " 0.29871566838658342,\n",
       " 0.33939909830236098,\n",
       " 0.34190026934138451,\n",
       " 0.32355661458684226,\n",
       " 0.35431725666524566,\n",
       " 0.3531749237009138]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_topics=optimal_num\n",
    "\n",
    "lda = LdaModel(corpus, num_topics=num_topics, id2word=text_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [u'makeamericagreatagain', u'trump2016', u'thank', u'trump', u'carson', u'keep', u'love', u'problem', u'new', u'job']\n",
      "----\n",
      "1 [u'politician', u'trump', u'border', u'tired', u'gop', u'hope', u'book', u'handle', u'america', u'incompetent']\n",
      "----\n",
      "2 [u'walker', u'talk', u'makeamericagreatagain', u'give', u'interview', u'a.m.', u'put', u'gov.', u'will', u'ill']\n",
      "----\n",
      "3 [u'thank', u'great', u'trump2016', u'tonight', u'interview', u'will', u'makeamericagreatagain', u'true', u'enjoy', u'new']\n",
      "----\n",
      "4 [u'trump', u'president', u'donald', u'thing', u'say', u'reagan', u'need', u'man', u'word', u'know']\n",
      "----\n",
      "5 [u'mccain', u'win', u'like', u'trump', u'john', u'lose', u'money', u'matter', u'cruz', u'go']\n",
      "----\n",
      "6 [u'speak', u'trump', u'poll', u'great', u'candidate', u'like', u'time', u'post', u'money', u'winner']\n",
      "----\n",
      "7 [u'vet', u'trump', u'truth', u'silent', u'mr.', u'class', u'while', u'care', u'primary', u'treat']\n",
      "----\n",
      "8 [u'poll', u'truth', u'lead', u'national', u'tell', u'number', u'hillary', u'lie', u'ronald', u'come']\n",
      "----\n",
      "9 [u'president', u'people', u'good', u'be', u'record', u'obama', u'change', u'what', u'free', u'job']\n",
      "----\n",
      "10 [u'thank', u'makeamericagreatagain', u'support', u'trump2016', u'deal', u'want', u'care', u'vote', u'hurt', u'veteran']\n",
      "----\n",
      "11 [u'great', u'look', u'crowd', u'forward', u'for', u'iowa', u'new', u'will', u'have', u'big']\n",
      "----\n",
      "12 [u'great', u'veteran', u'tell', u'thank', u'people', u'job', u'today', u'place', u'amazing', u'keep']\n",
      "----\n",
      "13 [u'america', u'great', u'make', u'trump', u'again', u'donald', u'need', u'love', u'thank', u'want']\n",
      "----\n",
      "14 [u'talk', u'know', u'people', u'like', u'want', u'trump', u'should', u'issue', u'good', u'ago']\n",
      "----\n",
      "15 [u'trump', u'poll', u'donald', u'rubio', u'jeb', u'illegal', u'new', u'gop', u'lead', u'bush']\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(num_topics):\n",
    "    print i,  [i[0] for i in lda.show_topic(i, topn = 10)]\n",
    "    print '----'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:datasci27]",
   "language": "python",
   "name": "conda-env-datasci27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
